\subsection{概要}

訓練データセットを $\mathcal{D} = \{(\mathbf{X}_n, \mathbf{Y}_n)\}_{n=1}^{N}$ とする．
ここで，$N$ は訓練画像の総数，$\mathbf{X}_n \in \mathbb{R}^{H \times W \times C}$ は $n$ 番目の入力画像（$C$はチャンネル数），
$\mathbf{Y}_n = \{y_{n,i,j}\}_{i,j} \in \mathbb{R}^{H \times W}$ は対応する正解マスクである．
MC Dropout による不確実性推定では，各画像に対して $T$ 回の確率的推論を行う．
$t$ 回目の推論（$t \in \{1, \ldots, T\}$）における予測確率マップを $\hat{\mathbf{Y}}_n^{(t)} = \{\hat{y}_{n,i,j}^{(t)}\}_{i,j}$ と表記する．

図\ref{method} に提案手法の概要を，アルゴリズム\ref{alg:proposed_method} に詳細なアルゴリズムを示す．
本手法の設計は，主に以下の2つの観点に基づいている．

第一に，学習サンプルに対する難易度評価を，学習プロセスの中で動的に更新する必要がある点である．
画像の「難しさ」は絶対的なものではなく，モデルの学習進捗によって変化する相対的なものである．
学習初期には困難であった画像も，学習が進むにつれてモデルが特徴を捉え，容易な画像へと変化しうる．
したがって，学習開始前に固定的に難易度を決定するのではなく，現在のモデルの状態に基づいて難易度を逐次再評価することで，
その時点でのモデルにとって確信を持てない画像に学習を集中できる．

第二に，難易度の定量化指標として，認識的不確実性が適している点である． 単なる予測誤差の大きさは，
画像のノイズや偶然的不確実性によっても増大するため，必ずしも「学習すれば改善できる難しさ」を表さない．
一方で，認識的不確実性は「モデルの知識不足」に起因するため，モデルが未学習のパターンや判断に迷っている領域を直接的に反映する．
この指標を用いることで，ノイズに影響されることなく，学習によって改善可能な「モデルにとってどれくらい確信を持てないか」を適切に定量化することが可能となる．

提案法では，学習中各画像に対して $\tau$ エポックごとに MC Dropout を用いて画像毎に複数枚推論を行い，予測のばらつきから不確実性を定量化する．
この不確実性情報は，モデルがその画像のセグメンテーションにおいてどの程度の確信を持てないかを反映する．
その後，この不確実性情報を画像単位に集約し，PolyDice Loss の形状を動的に制御することで，難しい画像には急峻な勾配を，簡単な画像には緩やかな勾配を与える．
更新された $\epsilon$ を次の $\tau$ エポック間の学習に適用することで，学習の進行度に応じて最適化の重み付けを動的に変化させる適応的学習を実現する．

\clearpage

\begin{figure}
    \includegraphics[width=\columnwidth]{figure/method.pdf}
    \caption{Overview of the proposed adaptive learning framework}
    \label{method}
\end{figure}

\clearpage

\begin{algorithm}[t]
    \caption{Uncertainty-based Adaptive PolyDice-1 Loss Learning}
    \label{alg:proposed_method}
    \begin{algorithmic}[1]
        \Require Training dataset $\mathcal{D}$, Max epochs $E$, Model $f_\theta$
        % ▼▼▼ E_0 の定義を「適応的学習開始エポック」として明確化 ▼▼▼
        \Require \textbf{Hyperparameters:} Adaptive start epoch $E_0$, Interval $\tau$, MC iterations $N$, Slope $k$, Range $[\epsilon_{\min}, \epsilon_{\max}]$
        
        \State Initialize model parameters $\theta$
        \State Initialize loss parameter $\epsilon_i \leftarrow 0$ for all images $x_i \in \mathcal{D}$
        
        \For{$e = 1$ \textbf{to} $E$}
            \Comment{\textbf{Step 1: Adaptive Control Phase}}
            % ▼▼▼ 論理的な整合性: E_0 (例:11) になった瞬間に最初の更新を行う ▼▼▼
            % これにより、e=1~10はSkipされ、e=11の学習「前」に更新される
            \If{$e \geq E_0$ \textbf{and} $(e - E_0) \pmod \tau = 0$}
                \State $List_D \leftarrow \emptyset$
                \For{each image $x_i \in \mathcal{D}$}
                    \State Perform $N$ stochastic inferences: $\{\hat{y}^{(n)}\}_{n=1}^N \leftarrow \text{MC\_Dropout}(x_i)$
                    % ... (中略) ...
                    \State Update $\epsilon_i \leftarrow \dots$
                \EndFor
            \Else
                % ▼▼▼ 明示的に書くことで誤解を防ぐ（省略可） ▼▼▼
                \State \Comment{Keep $\epsilon_i$ fixed (Initial Training / Interval)}
            \EndIf

            \State
            \Comment{\textbf{Step 2: Training Phase}}
            \For{each batch $(\mathbf{x}, \mathbf{y}) \in \mathcal{D}$}
                % ... (中略) ...
                \State Update parameters: $\theta \leftarrow \theta - \eta \nabla_\theta \mathcal{L}$
            \EndFor
        \EndFor
        \State \Return Trained parameters $\theta$
    \end{algorithmic}
\end{algorithm}

\clearpage

\subsection{不確実性に基づく画像難易度の定量化}

\subsubsection{学習中のMC Dropout推論}

提案法では，学習プロセスを初期学習期間と適応的学習期間の2段階に分割する．
エポック $1$ から $E_0 - 1$ までの期間は初期学習期間とし，損失形状パラメータ $\epsilon$ を$0$に固定して学習を行う．
この期間を設ける理由は，学習初期のモデルは特徴表現が未成熟であり，この段階での不確実性は画像の本質的な難易度よりもモデルの初期化に依存するためである．
$E_0$はモデルが基礎的なセグメンテーション能力を獲得するのに十分なエポック数として設定する．

適応的学習期間（$e \geq E_0$）においては，周期 $\tau$ ごとに不確実性の再評価と $\epsilon$ の更新を行う．
すなわち，更新は $e \in \{E_0, E_0+\tau, E_0+2\tau, \ldots\}$ を満たすエポックの学習開始前に実行される．
更新の際は，その時点のモデルパラメータ $\mathbf{W}$ を固定し，訓練データの各画像 $x \in \mathcal{X}$ に対して Dropout 率 $p \in (0,1)$ で $N$ 回の確率的推論を行う．
得られる予測集合を $\{\hat{\mathbf{Y}}^{(n)}\}_{n=1}^{N}$ とする：
%
\begin{equation}
    \hat{\mathbf{Y}}^{(n)} = f_{\mathbf{W}}(x; \mathbf{z}^{(n)}), \quad \mathbf{z}^{(n)} \sim \text{Bernoulli}(1-p)
\end{equation}
%
ここで，$\mathbf{z}^{(n)}$ は $n$ 回目の推論における Dropout マスクであり，$\hat{\mathbf{Y}}^{(n)}$ はその予測確率マップである．
この確率的推論により得られる予測のばらつきから，モデルの認識的不確実性を定量化する．

\subsubsection{ピクセル単位の不確実性指標の計算}
得られた $N$ 枚の予測画像に対し，ピクセル単位の不確実性指標として
認識的不確実性を直接捉えることができる相互情報量 $I_{i,j}$ を計算する．

\begin{equation}
    I_{i, j} = H(\bar{y}_{i, j}) - \frac{1}{N}\sum_{n=1}^{N} H(\hat{y}_{i, j}^{(n)})
\end{equation}

ここで $H(\cdot)$ はエントロピー関数，$\bar{y}_{i, j}$ は予測の平均を表す．
この相互情報量はモデルパラメータの不確実性を反映しており，値が高い領域はモデルが十分に学習できていないことを示唆する．

\subsubsection{画像単位への集約}
医用画像セグメンテーションでは，背景領域が画像の大部分を占める一方で，関心領域である病変部は極めて小さいクラス不均衡が存在する．
背景領域は一般に推論が容易であり，その不確実性は極めて低い値をとる傾向がある． そのため，画像全体で不確実性の平均を算出すると，
大量の背景画素による低い値が難易度指標全体を支配してしまい，本来捉えるべき病変部の局所的な難易度を適切に定量化できない可能性がある．
したがって，病変検出の難易度を鋭敏に反映させるため，本手法では正解画像における病変領域に限定して相互情報量の平均を算出する．

画像領域全体を $\Omega$，正解マスクにおける陽性領域の画素集合を $\mathcal{P} = \{(i,j) \in \Omega \mid y_{i,j} = 1\}$ とする．
ここで，算出される相互情報量には突発的なノイズや極端な外れ値が含まれる可能性があり，これらが難易度指標の定量化を不安定にさせる要因となる．
そのため，スコアの算出に先立ち，統計的な外れ値除去を行う．
具体的には，領域 $\mathcal{P}$ 内の相互情報量の平均を $\mu_{\mathcal{P}}$，標準偏差を $\sigma_{\mathcal{P}}$ とし，有効な画素集合 $\mathcal{P}'$ を以下のように定義する．
\begin{equation}
    \mathcal{P}' = {(i,j) \in \mathcal{P} \mid \mu_{\mathcal{P}} - 2\sigma_{\mathcal{P}} \leq I_{i,j} \leq \mu_{\mathcal{P}} + 2\sigma_{\mathcal{P}} }
\end{equation}


この有効集合 $\mathcal{P}'$ を用いて，画像全体の難易度スコア $D$ は次式で算出される．
\begin{equation}
        D = \frac{1}{|\mathcal{P}'|} \sum_{(i,j) \in \mathcal{P}'} I_{i,j}
\end{equation}
ここで，$|\mathcal{P}'|$ は外れ値除去後の陽性領域の画素数を表す．

次に，各サンプルの相対的な難易度を決定するため，データセット全体の難易度スコア分布に基づいて正規化を行う．
ここでの目的は，画像毎の数値的なスケールの差異を吸収し，各画像が分布全体の中で相対的にどの程度難しいかを評価することである．
算出された全画像のスコア集合における $q$ パーセンタイル値を $D_q$，標準偏差を $\sigma_D$ とすると，正規化されたスコア $D_{\text{norm}}$ は次のように計算される．

\begin{equation}
    D_{\text{norm}} = \frac{D - D_{q}}{\sigma_D + \delta}
\end{equation}
ここで，式中の$\delta$ は数値的安定性のための微小定数である．
$D_q$ による減算は，後述する制御関数の中心点を入力を合わせるための中心化である．
分布の平均値ではなく$q$パーセンタイル値を用いることで，容易なサンプルが多数を占める分布においても，
難易度の基準点を柔軟に設定し，外れ値の影響を受けずに困難な画像の難易度を定量化可能である．
$\sigma_D$ による除算は尺度の統一であり，難易度の変動幅を統一することで，
制御関数の感度がデータセットごとの不確実性のスケールに依存しないように調整する役割を持つ．

\subsection{適応的損失形状制御}

\subsubsection{制御関数の設計}
得られた難易度指標 $D_{\text{norm}}$ に基づき，PolyDice-1 Loss の形状パラメータ $\epsilon$ を動的に更新する．
更新式には以下のシグモイドベースの制御関数を用いる．

\begin{equation}
    \sigma(x) = \frac{1}{1 + \exp(-kx)}
\end{equation}
\begin{equation}
    \epsilon = \epsilon_{\text{min}} + (\epsilon_{\text{max}} - \epsilon_{\text{min}}) \sigma(D_{\text{norm}})
\end{equation}

ここで，$k$ は関数の感度を制御するハイパーパラメータであり，$\epsilon_{\text{min}}, \epsilon_{\text{max}}$ は $\epsilon$ の変動範囲である．
本手法でシグモイド関数を採用する理由は，有界性と滑らかさにある．
ステップ関数のような急激な切り替えは学習の安定性を損なう恐れがあり，
線形関数ではパラメータ$\epsilon$が適切な範囲$[\epsilon_{\text{min}}, \epsilon_{\text{max}}]$ を逸脱する可能性がある．
シグモイド関数を用いることで，難易度が低い領域から高い領域への遷移を滑らかに行いつつ，出力値を常に所定の範囲内に厳密に制約することが可能となる．

この制御により，難しい画像に対して大きな$\epsilon$を割り当てることで，損失関数の勾配が急峻になる．これは，同じ予測誤差に対して
より大きな損失値と勾配を与えることを意味し，結果として難しい画像からの学習信号が相対的に強化される．
一方，すでに十分に学習できている簡単な画像には小さな$\epsilon$を割り当て，過学習を防ぎつつ学習リソースを難しい画像に集中させる．
更新された $\epsilon$ は次の $\tau$ エポック間の学習に適用され，これによりモデルは困難な画像の学習を重点的に行うことが可能となる．

\subsubsection{学習アルゴリズム}
学習プロセスは難易度評価と損失パラメータ更新を行う適応的制御と，
実際にモデルパラメータを更新する学習段階の2つで構成される．

学習開始時，まずモデルパラメータ $\mathbf{W}$ を初期化し，全ての画像に対する損失形状パラメータ $\epsilon$ を $0$ に初期化する．
エポック $1$ から $E_0 - 1$ までの初期学習期間では，適応的制御は行われず，
PolyDice-1 Lossにおいて$\epsilon=0$とした際の学習が行われる．これにより，モデルは不確実性推定に必要な最低限の特徴表現を獲得する．

適応的学習期間（$e \geq E_0$）に入ると，$\tau$ エポックごとに適応的制御が実行される．
ここでは，直前のセクションで述べた手順に従い，MC Dropout推論，不確実性指標の算出，正規化を経て，各画像の $\epsilon$ が更新される．
適応的制御の段階ではモデルパラメータ$\mathbf{W}$は固定されており，データに対する重み付け$\epsilon$の更新のみが行われることに注意されたい．

続く学習段階では，更新された$\epsilon$ を用いて，データセットに対するミニバッチ学習を行う．
ここでは，難易度が高いと判定された画像には大きな $\epsilon$ が，低い画像には小さな $\epsilon$ が適用された状態で損失関数 $\mathcal{L}$ が計算され，
勾配降下法によりモデルパラメータ $\boldsymbol{\theta}$ が最適化される．
このサイクルを繰り返すことで，モデルの学習に応じて困難な画像の学習を重点的にに行うことが可能となる．